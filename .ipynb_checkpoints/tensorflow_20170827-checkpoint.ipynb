{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "# 1次元のデータを生成\n",
    "data_1d = np.random.normal(size=data_size)\n",
    "# プレースホルダを作成\n",
    "x_input_1d = tf.placeholder(dtype=tf.float32, shape=[data_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer_1d(input_1d, my_filter):\n",
    "    # 1次元の入力を4次元にする\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # ストライド1で畳み込みを実行\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,1,1,1], padding=\"VALID\")\n",
    "    # 余分な次元を削除\n",
    "    conv_output_1d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "my_convolution_output = conv_layer_1d(x_input_1d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  activation(input_1d):\n",
    "    return(tf.nn.relu(input_1d))\n",
    "\n",
    "# 活性化層を作成\n",
    "my_activation_output = activation(my_convolution_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_pool(input_1d, width):\n",
    "    # 1次元の入力を4次元にする\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # ストライド1でマックスプーリンを実行\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, 1, width, 1], strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "    # 余分な次元を削除\n",
    "    pool_output_1d = tf.squeeze(pool_output)\n",
    "    return(pool_output_1d)\n",
    "\n",
    "# マックスプーリング層を作成\n",
    "my_maxpool_output = max_pool(my_activation_output, width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_outputs):\n",
    "    # 重みを作成\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_outputs]]))\n",
    "    # 重みを初期化\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # バイアスを初期化\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # 入力を2次元配列にする\n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    # 全結合演算（行列の乗算とバイアスの追加）を実行\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    # 余分な次元を削除\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n",
    "\n",
    "# 全結合層を作成\n",
    "my_full_output  = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_1d: data_1d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = array of length 25\n",
      "Convolution w/filter, length = 5, stride size = 1, results in an array of length 21:\n",
      "[-1.05097878 -0.30860162  0.09815298 -0.35026589 -0.84521806  1.70141625\n",
      " -0.29660401  2.65369606  0.77026397  0.13656747  1.08798301 -2.41421509\n",
      "  1.12136614 -2.98701859  1.14287055 -0.67281902  1.08716643 -1.01938283\n",
      "  0.70333934 -2.74435186 -0.65808177]\n",
      "¥nInput = the above array of length 21\n",
      "ReLU element wise returns the array of length 21:\n",
      "[ 0.          0.          0.09815298  0.          0.          1.70141625\n",
      "  0.          2.65369606  0.77026397  0.13656747  1.08798301  0.\n",
      "  1.12136614  0.          1.14287055  0.          1.08716643  0.\n",
      "  0.70333934  0.          0.        ]\n",
      "¥nInput = the above array of length 21\n",
      "MaxPool, window length = 5, stride size = 1, results in the array of length 17\n",
      "[ 0.09815298  1.70141625  1.70141625  2.65369606  2.65369606  2.65369606\n",
      "  2.65369606  2.65369606  1.12136614  1.12136614  1.14287055  1.14287055\n",
      "  1.14287055  1.14287055  1.14287055  1.08716643  1.08716643]\n",
      "¥nInput = the above array of length 17\n",
      "Fully connnected layer on all four rows with five outputs:\n",
      "[-0.3039794  -1.92077994  0.90005326 -1.34575462 -0.7554847 ]\n"
     ]
    }
   ],
   "source": [
    "# 畳み込み層の出力\n",
    "print('Input = array of length 25')\n",
    "print('Convolution w/filter, length = 5, stride size = 1, results in an array of length 21:')\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "\n",
    "# 活性化層の出力\n",
    "print('¥nInput = the above array of length 21')\n",
    "print('ReLU element wise returns the array of length 21:')\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "\n",
    "# マックスプーリング層の出力\n",
    "print('¥nInput = the above array of length 21')\n",
    "print('MaxPool, window length = 5, stride size = 1, results in the array of length 17')\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "\n",
    "# 全結合層への出力\n",
    "print('¥nInput = the above array of length 17')\n",
    "print('Fully connnected layer on all four rows with five outputs:')\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size = [10,10]\n",
    "# 2次元のデータを生成\n",
    "data_2d = np.random.normal(size=data_size)\n",
    "# プレースホルダを作成\n",
    "x_input_2d = tf.placeholder(dtype=tf.float32, shape=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    # 2次元の入力を4次元にする\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # 畳み込みを実行（ストライドの違いに注意）\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,2,2,1], padding=\"VALID\")\n",
    "    # 余分な次元を削除\n",
    "    conv_output_2d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_2d)\n",
    "\n",
    "# 畳み込みフィルタを作成\n",
    "my_filter = tf.Variable(tf.random_normal(shape=[2,2,1,1]))\n",
    "# 畳み込み層を作成\n",
    "my_convolution_output = conv_layer_2d(x_input_2d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(input_2d):\n",
    "    return(tf.nn.relu(input_2d))\n",
    "\n",
    "# 活性化層を作成\n",
    "my_activation_output = activation(my_convolution_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_pool(input_2d, width, height):\n",
    "    # 2次元の入力を4次元にする\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # マックスプーリングを実行\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, height, width, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    # 余分な次元を削除\n",
    "    pool_output_2d = tf.squeeze(pool_output)\n",
    "    return(pool_output_2d)\n",
    "\n",
    "# マックスプーリング層を作成\n",
    "my_maxpool_output = max_pool(my_activation_output, width=2, height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_outputs):\n",
    "    # 1次元にする\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    # 重みを作成\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_outputs]]))\n",
    "    # 重みを初期化\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # バイアスを初期化\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # 2次元にする\n",
    "    input_2d = tf.expand_dims(flat_input, 0)\n",
    "    # 全結合演算を実行\n",
    "    full_output = tf.add(tf.matmul(input_2d, weight), bias)\n",
    "    # 余分な次元を削除\n",
    "    full_output_2d = tf.squeeze(full_output)\n",
    "    return(full_output_2d)\n",
    "\n",
    "#全結合層を作成\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_2d: data_2d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = [10,10] array\n",
      "[2, 2] Convolution, stride size = [2, 2], results in the [5, 5] array\n",
      "[[ 2.66505671  2.94650412 -1.06595957 -0.53130883 -1.55073035]\n",
      " [ 1.76208854 -0.11624587  0.48761457 -0.08125717 -0.05775905]\n",
      " [-2.07696009  0.95554638 -0.13551201  0.44764209 -0.08830321]\n",
      " [ 0.57219076  1.04545355  1.43570781 -0.48084152  1.78725421]\n",
      " [-0.24305016  1.8197875  -0.80240077 -0.38667798  0.35234463]]\n",
      "¥nInput = the above [5, 5] array\n",
      "ReLU element wise returns the [5, 5] array\n",
      "[[ 2.66505671  2.94650412  0.          0.          0.        ]\n",
      " [ 1.76208854  0.          0.48761457  0.          0.        ]\n",
      " [ 0.          0.95554638  0.          0.44764209  0.        ]\n",
      " [ 0.57219076  1.04545355  1.43570781  0.          1.78725421]\n",
      " [ 0.          1.8197875   0.          0.          0.35234463]]\n",
      "¥nInput = the above [5, 5] array\n",
      "MaxPool, stride size = [1, 1], results in the [4, 4] array\n",
      "[[ 2.94650412  2.94650412  0.48761457  0.        ]\n",
      " [ 1.76208854  0.95554638  0.48761457  0.44764209]\n",
      " [ 1.04545355  1.43570781  1.43570781  1.78725421]\n",
      " [ 1.8197875   1.8197875   1.43570781  1.78725421]]\n",
      "¥nInput = the above [4, 4] array\n",
      "Fully connected layer on all 4 rows results in 5 outputs:\n",
      "[-0.18444601  0.81321925 -0.14608191 -0.90578061  0.38752931]\n"
     ]
    }
   ],
   "source": [
    "# 畳み込み層の出力\n",
    "print('Input = [10,10] array')\n",
    "print('[2, 2] Convolution, stride size = [2, 2], results in the [5, 5] array')\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "# 活性化層の出力\n",
    "print('¥nInput = the above [5, 5] array')\n",
    "print('ReLU element wise returns the [5, 5] array')\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "#マックスプーリング層の出力\n",
    "print('¥nInput = the above [5, 5] array')\n",
    "print('MaxPool, stride size = [1, 1], results in the [4, 4] array')\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "# 全結合層の出力\n",
    "print('¥nInput = the above [4, 4] array')\n",
    "print('Fully connected layer on all 4 rows results in 5 outputs:')\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-345f9fafdec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;31m# 目的変数を抽出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0my_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbirth_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mcols_of_interest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'AGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LWT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RACE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SMOKE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PLT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'HT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UI'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;31m# 予測変数を抽出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-345f9fafdec7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;31m# 目的変数を抽出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0my_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbirth_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mcols_of_interest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'AGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LWT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RACE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SMOKE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PLT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'HT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UI'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;31m# 予測変数を抽出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# name of data file\n",
    "birth_weight_file = 'birth_weight.csv'\n",
    "\n",
    "# データをダウンロードし、データファイルを作成\n",
    "if not os.path.exists(birth_weight_file):\n",
    "    birthdata_url = 'https://github.com/nfmcclure/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n",
    "    birth_file = requests.get(birthdata_url)\n",
    "    birth_data  = birth_file.text.split('¥r¥n')\n",
    "    birth_header = birth_data[0].split('¥t')\n",
    "    birth_data = [[float(x) for x in y.split('¥t') if len(x)>=1] for y in birth_data[1:] if len(y)>=1]\n",
    "    with open(birth_weight_file, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([birth_header])\n",
    "        f.close()\n",
    "        \n",
    "# データをメモリに読み込む\n",
    "birth_data = []\n",
    "with open(birth_weight_file, newline='') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    birth_header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        birth_data.append(row)\n",
    "        \n",
    "birth_data = [[float(x) for x in row] for row in birth_data]\n",
    "\n",
    "# 目的変数を抽出\n",
    "y_vals = np.array([x[8] for x in birth_data])\n",
    "cols_of_interest = ['AGE', 'LWT', 'RACE', 'SMOKE', 'PLT', 'HT', 'UI']\n",
    "# 予測変数を抽出\n",
    "x_vals = np.array([[x[ix] for ix, feature in enumerate(birth_header) if feature in cols_of_interest] for x in birth_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "seed = 3\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0,8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_vals_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-32e1ccebe8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcol_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcol_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_vals_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx_vals_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_vals_train' is not defined"
     ]
    }
   ],
   "source": [
    "def normalize_cols(m):\n",
    "    col_max = m.max(axis=0)\n",
    "    col_min = m.min(axis=0)\n",
    "    return (m - col_min) / (col_max - col_min)\n",
    "\n",
    "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
    "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(shape, st_dev):\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return(weight)\n",
    "\n",
    "def init_bias(shape, st_dev):\n",
    "    bias = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[None, 7], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, weights, biases):\n",
    "    layer = tf.add(tf.matmul(input_layer, weights), biases)\n",
    "    return(tf.nn.relu(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# １つ目の層（25個のノードを持つ隠れ層）を作成\n",
    "weight_1 = init_weight(shape=[7, 25], st_dev=10.0)\n",
    "bias_1 = init_bias(shape=[25], st_dev=10.0)\n",
    "layer_1 = fully_connected(x_data, weight_1, bias_1)\n",
    "\n",
    "# 2つ目の層（10個のノードを持つ隠れ層）を作成\n",
    "weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n",
    "bias_2 = init_bias(shape=[10], st_dev=10.0)\n",
    "layer_2 = fully_connected(layer_1, weight_2, bias_2)\n",
    "\n",
    "# 3つ目の層（3個のノードを持つ隠れ層）を作成\n",
    "weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n",
    "bias_3 = init_bias(shape=[3], st_dev=10.0)\n",
    "layer_3 = fully_connected(layer_2, weight_3, bias_3)\n",
    "\n",
    "# 出力層（1個の出力）を作成\n",
    "weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n",
    "bias_4 = init_bias(shape=[1], st_dev=10.0)\n",
    "final_output = fully_connected(layer_3, weight_4, bias_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数を作成\n",
    "loss = tf.reduce_mean(tf.abs(y_target - final_output))\n",
    "\n",
    "# 最適化関数を作成\n",
    "my_opt = tf.train.AdamOptimizer(0.05)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# 変数を初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_vals_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e851959e0d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# バッチを選択するためのインデックスをランダムに選択\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrand_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# ランダムな値でバッチを取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrand_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_vals_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_vals_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 損失ベクトルを初期化\n",
    "loss_vec = []\n",
    "test_loss = []\n",
    "for i in range(200):\n",
    "    # バッチを選択するためのインデックスをランダムに選択\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    # ランダムな値でバッチを取得\n",
    "    rand_x = x_vals_train[rand_index]\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    # トレーニングステップを実行\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    \n",
    "    # トレーニングセットの損失値を保存\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
    "    test_loss.append(test_temp_loss)\n",
    "    \n",
    "    if (i+1)%25==0:\n",
    "        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_vec, 'k-', label='Train Loss')\n",
    "plt.plot(test_loss, 'r--', label='Test Loss')\n",
    "plt.title('Loss (MSE) per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actuals = np.array([x[1] for x in birth_data])\n",
    "test_actuals = actuals[test_indices]\n",
    "train_actuals = actuals[train_indices]\n",
    "test_preds = [x[0] for x in sess.run(final_output, feed_dict={x_data: x_vals_test})]\n",
    "train_preds = [x[0] for x in sess.run(final_output, feed_dict={x_data: x_vals_train})]\n",
    "test_preds = np.array([1.0 if x<2500.0 else 0.0 for x in test_preds])\n",
    "train_preds = np.array([1.0 if x<2500.0 else 0.0 for x in train_preds])\n",
    "\n",
    "# 正解率を出力\n",
    "test_acc = np.mean([x==y for x,y in zip(test_preds, test_actuals)])\n",
    "train_acc = np.mean([x==y for x,y in zip(train_preds, train_actuals)])\n",
    "print('On predicting the category of low birthweight from regression output (<2500g):')\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "print('Train Accuracy: {}'.format(train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7線形モデルの予測を改善する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import os.path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データをダウンロードし、データファイルを作成\n",
    "if not os.path.exists(birth_weight_file):\n",
    "    birthdata_url = 'httpd://github.com/nfmcclure/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat''\n",
    "    birth_file = request.get(birthdata_url)\n",
    "    birth_data = birth_file.text.split('¥r¥n')\n",
    "    birth_header = birth_data[0].split('¥t')\n",
    "    birth_data = [[float(x) for x in y.split('¥t') if len(x) >=1] for y in birth_data[1:] if len(y)>=1]\n",
    "    with open(birth_weight_file, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(birth_data)\n",
    "        f.close()\n",
    "        \n",
    "# データをメモリに読み込む\n",
    "birth_data = []\n",
    "with open(birth_weight_file, newline='') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    birth_header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        birth_data.append(row)\n",
    "        \n",
    "birth_data = [[float(x) for x in row] for row in birth_data]\n",
    "\n",
    "# 目的変数を抽出\n",
    "y_vals = np.array([x[1] for x in birth_data])\n",
    "# 説明変数を抽出\n",
    "x_vals = np.array([x[2:9] for x in birth_data])\n",
    "\n",
    "# データセットをトレーニングセットとテストセットに分割\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals)))- set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "a_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "# min-maxスケーリングを使って正規化\n",
    "def normalize_cols(m):\n",
    "    col_max = m.max(axis=0)\n",
    "    col_min = m.min(axis=0)\n",
    "    return (m - col_min) / (col_max - col_min)\n",
    "\n",
    "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
    "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
